# Architecture actuelle du pipeline RAGpy

**Date de cr√©ation** : 2025-10-21  
**Derni√®re mise √† jour** : 2025-11-22 (analyse compl√®te par agents sp√©cialis√©s)  
**Objectif** : Documenter l'architecture existante compl√®te avec analyse d√©taill√©e

---

## Vue d'ensemble du syst√®me

**RAGpy** est un pipeline sophistiqu√© de **Retrieval-Augmented Generation (RAG)** con√ßu pour traiter des documents acad√©miques et les pr√©parer pour le stockage dans des bases vectorielles. Le syst√®me combine une interface web moderne (FastAPI) avec un pipeline de traitement modulaire pour l'extraction, le chunking, l'embedding et l'insertion vectorielle.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 PIPELINE COMPLET RAGpy (2025-11-22)             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

ARCHITECTURE MODULAIRE:
‚îú‚îÄ‚îÄ app/                  # Interface web FastAPI (point d'entr√©e)
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # Orchestrateur web (1,543 lignes)
‚îÇ   ‚îú‚îÄ‚îÄ utils/           # Int√©gration Zotero
‚îÇ   ‚îú‚îÄ‚îÄ static/          # Assets CSS, favicon
‚îÇ   ‚îî‚îÄ‚îÄ templates/       # Templates HTML (Jinja2)
‚îú‚îÄ‚îÄ scripts/             # Pipeline de traitement
‚îÇ   ‚îú‚îÄ‚îÄ rad_dataframe.py # PDF/Zotero ‚Üí CSV (OCR)
‚îÇ   ‚îú‚îÄ‚îÄ rad_chunk.py     # Chunking + embeddings
‚îÇ   ‚îî‚îÄ‚îÄ rad_vectordb.py  # Insertion bases vectorielles
‚îú‚îÄ‚îÄ core/               # Mod√®les de donn√©es unifi√©s
‚îÇ   ‚îî‚îÄ‚îÄ document.py     # Classe Document abstraite
‚îú‚îÄ‚îÄ ingestion/          # Modules d'ingestion
‚îÇ   ‚îî‚îÄ‚îÄ csv_ingestion.py # Ingestion CSV directe
‚îú‚îÄ‚îÄ config/             # Configuration YAML
‚îú‚îÄ‚îÄ tests/              # Suite de tests
‚îú‚îÄ‚îÄ uploads/            # Sessions utilisateur
‚îî‚îÄ‚îÄ logs/              # Logs application

FLUX DE DONN√âES:
Input Sources ‚Üí Data Extraction ‚Üí Document Processing ‚Üí Vector Storage
     ‚Üì              ‚Üì                    ‚Üì                  ‚Üì
‚îú‚îÄ Zotero+PDFs    CSV Generation    Chunking/Embedding   Pinecone
‚îú‚îÄ Direct CSV  ‚Üí     output.csv  ‚Üí    JSON stages    ‚Üí   Weaviate
‚îî‚îÄ Manual Files                                          Qdrant
```

---

## Analyse de l'architecture (2025-11-22)

### üèóÔ∏è **Qualit√© du code et structure**

#### **Points forts identifi√©s**
- **Architecture modulaire excellente** avec s√©paration claire des responsabilit√©s
- **Classe Document unifi√©e** garantissant la compatibilit√© pipeline
- **Logging structur√©** avec rotation et niveaux appropri√©s
- **Gestion d'erreurs sophistiqu√©e** avec m√©canismes de retry
- **Support multi-providers** pour optimisation des co√ªts

#### **Points d'am√©lioration critiques**
- **app/main.py trop volumineux** (1,543 lignes) ‚Üí refactorisation n√©cessaire
- **M√©tadonn√©es hardcod√©es** dans 4 emplacements critiques
- **Validation d'entr√©e insuffisante** sur plusieurs endpoints
- **D√©pendances non √©pingl√©es** ‚Üí risques de s√©curit√©
- **Conventions de nommage mixtes** (fran√ßais/anglais)

#### **Dette technique majeure**
```python
# Probl√®me: M√©tadonn√©es hardcod√©es limitant l'extensibilit√©
# Fichier: rad_chunk.py:250-263, rad_vectordb.py (3 emplacements)
chunk_metadata = {
    "title": row_data.get("title", ""),
    "authors": row_data.get("authors", ""),
    # ... 8 autres champs hardcod√©s
}
# Impact: Colonnes CSV personnalis√©es perdues ‚Üí Limitation CSV
```

### üöÄ **API et endpoints**

L'application FastAPI expose **16 endpoints principaux** couvrant l'int√©gralit√© du pipeline :

#### **Endpoints de traitement de fichiers**
- `POST /upload_zip` - Upload archives Zotero
- `POST /upload_csv` - Ingestion CSV directe 
- `POST /upload_stage_file/{stage}` - Artifacts interm√©diaires

#### **Pipeline de traitement**
- `POST /process_dataframe` - Extraction PDF/OCR
- `POST /initial_text_chunking` - G√©n√©ration chunks
- `POST /dense_embedding_generation` - Embeddings OpenAI
- `POST /sparse_embedding_generation` - Embeddings spaCy
- `POST /upload_db` - Insertion bases vectorielles

#### **Fonctionnalit√©s avanc√©es**
- **Server-Sent Events (SSE)** pour suivi temps r√©el
- **Gestion de sessions** avec r√©pertoires uniques
- **Configuration dynamique** des credentials
- **Int√©gration Zotero** bidirectionnelle

#### **S√©curit√© actuelle**
```python
# Configuration CORS permissive (d√©veloppement)
app.add_middleware(CORSMiddleware, allow_origins=["*"])
# Recommandation: Restreindre en production
```

### üîÑ **Pipeline de traitement des donn√©es**

#### **Flux de donn√©es end-to-end**

```mermaid
graph TD
    A[Sources multiples] --> B[Extraction normalis√©e]
    B --> C[Document unifi√©]
    C --> D[Chunking intelligent]
    D --> E[Embeddings hybrides]
    E --> F[Stockage vectoriel]
    
    A1[Zotero JSON + PDFs] --> B1[OCR Multi-provider]
    A2[CSV Direct] --> B2[Mapping colonnes]
    A3[Fichiers manuels] --> B3[Traitement unifi√©]
    
    B1 --> C1[output.csv]
    B2 --> C1
    B3 --> C1
    
    C1 --> D1[RecursiveTextSplitter]
    D1 --> D2[Recodage GPT conditionnel]
    D2 --> E1[OpenAI dense 3072D]
    E1 --> E2[spaCy sparse 100kD]
    E2 --> F1[Pinecone/Weaviate/Qdrant]
```

#### **Transformations de donn√©es critiques**

**1. Hi√©rarchie OCR avec fallback intelligent**
```python
# Ordre de priorit√© automatique
Mistral OCR (Markdown) ‚Üí OpenAI Vision ‚Üí PyMuPDF Legacy
     ‚Üì                      ‚Üì              ‚Üì
   Skip recodage         Recodage GPT   Recodage lourd
   (√©conomie 80%)       (co√ªt standard) (co√ªt maximum)
```

**2. Chunking adaptatif**
- **Tokens**: 1000 (overlap 150) pour `text-embedding-3-large`
- **S√©parateurs**: `["\n\n", "#", "##", "\n", " ", ""]`
- **Recodage conditionnel**: Skip si `texteocr_provider="mistral"` ou `"csv"`

**3. Embeddings hybrides optimis√©s**
```python
# Dense: Similarit√© s√©mantique (OpenAI)
embedding_dense = client.embeddings.create(
    input=chunks, model="text-embedding-3-large"
)  # 3072 dimensions

# Sparse: Correspondance lexicale (spaCy fran√ßais)
sparse_features = extract_sparse_features(text)  # TF normalis√©
# Hash-based indexing: hash(lemma) % 100,000 ‚Üí 100k dimensions
```

#### **Points d'int√©gration cl√©s**

**Classe Document unifi√©e** (architecture solide):
```python
@dataclass
class Document:
    texteocr: str                    # Variable pivot unique
    meta: Dict[str, Any]            # M√©tadonn√©es extensibles
    
    def to_dict(self) -> Dict[str, Any]:
        return {"texteocr": self.texteocr, **self.meta}
```

**Gestion des providers OCR**:
```python
# Auto-d√©tection et fallback
provider_hierarchy = ["mistral", "openai", "legacy"]
ocr_result = extract_text_with_ocr(pdf_path, return_details=True)
# ‚Üí OCRResult(text, provider) pour tra√ßabilit√© compl√®te
```

### ‚öôÔ∏è **Configuration et environnement**

#### **Gestion des variables d'environnement**

**Variables obligatoires**:
```bash
OPENAI_API_KEY=sk-...  # Embeddings + recodage
```

**Variables d'optimisation**:
```bash
# R√©duction co√ªts (~75% √©conomie)
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_DEFAULT_MODEL=openai/gemini-2.5-flash

# OCR premium
MISTRAL_API_KEY=...
MISTRAL_OCR_MODEL=mistral-ocr-latest
```

**Bases vectorielles** (au moins une requise):
```bash
# Pinecone
PINECONE_API_KEY=pcsk-...
PINECONE_ENV=https://your-index.svc.aped.pinecone.io

# Weaviate
WEAVIATE_URL=https://your-cluster.weaviate.network
WEAVIATE_API_KEY=...

# Qdrant  
QDRANT_URL=https://your-cluster.qdrant.tech
QDRANT_API_KEY=...
```

**Int√©gration Zotero** (recherche acad√©mique):
```bash
ZOTERO_API_KEY=...     # G√©n√©ration notes automatiques
ZOTERO_USER_ID=...     # Auto-d√©tect√© depuis exports
ZOTERO_GROUP_ID=...    # Support biblioth√®ques de groupe
```

#### **Configuration CSV flexible**

```yaml
# config/csv_config.yaml
csv:
  text_column: "text"           # Colonne source ‚Üí texteocr
  encoding: "auto"              # D√©tection chardet
  delimiter: ","
  meta_columns: []              # Si vide: toutes sauf text_column
  skip_empty: true              # Ignorer lignes vides
  add_row_index: true           # M√©tadonn√©es row_index
  source_type: "csv"            # Type pour Document
```

#### **Patterns de d√©ploiement**

**D√©marrage serveur**:
```bash
# D√©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Production (via script CLI)
./ragpy_cli.sh start  # Gestion arri√®re-plan + logs
```

**Structure de sessions**:
```
uploads/
‚îú‚îÄ‚îÄ session_abc123/          # Session utilisateur unique
‚îÇ   ‚îú‚îÄ‚îÄ uploaded_files/      # Archives/CSV upload√©s
‚îÇ   ‚îú‚îÄ‚îÄ output.csv          # R√©sultat extraction
‚îÇ   ‚îú‚îÄ‚îÄ output_chunks.json  # Chunks initiaux
‚îÇ   ‚îú‚îÄ‚îÄ output_chunks_with_embeddings.json      # + Embeddings denses
‚îÇ   ‚îú‚îÄ‚îÄ output_chunks_with_embeddings_sparse.json  # + Embeddings sparses
‚îÇ   ‚îî‚îÄ‚îÄ *.log              # Logs sp√©cifiques session
```

### üîç **Int√©grations externes**

#### **Services LLM et OCR**
- **OpenAI**: Embeddings (`text-embedding-3-large`) + completion (`gpt-4o-mini`)
- **OpenRouter**: Alternative √©conomique (75% moins cher)
- **Mistral**: OCR premium avec sortie Markdown
- **spaCy**: NLP fran√ßais (`fr_core_news_md`) pour embeddings sparse

#### **Bases vectorielles support√©es**
- **Pinecone**: Hybrid search (dense + sparse), namespaces
- **Weaviate**: Multi-tenant, hybrid search
- **Qdrant**: Vector similarity, local/cloud

#### **Recherche acad√©mique**
- **Zotero**: Extraction m√©tadonn√©es + g√©n√©ration notes automatiques
- **Support PDF**: OCR multi-provider avec fallback
- **Export bidirectionnel**: Notes g√©n√©r√©es ‚Üí biblioth√®que Zotero

---

## Points critiques pour l'ingestion CSV

### üéØ **Variable pivot unique: `texteocr`**

| Point de cr√©ation/consommation | Fichier | Ligne | Status |
|-------------------------------|---------|-------|--------|
| **Cr√©ation (OCR)** | rad_dataframe.py | 508 | ‚úÖ Stable |
| **Cr√©ation (CSV)** | csv_ingestion.py | 377 | ‚úÖ Impl√©ment√© |
| **Consommation (chunking)** | rad_chunk.py | 199 | ‚úÖ Unifi√© |

**Conclusion**: L'abstraction `texteocr` fonctionne parfaitement pour unifier toutes les sources d'ingestion.

### ‚ö†Ô∏è **M√©tadonn√©es hardcod√©es (probl√®me majeur)**

| Emplacement | Fichier | Ligne | Impact | Priorit√© |
|------------|---------|-------|--------|----------|
| Cr√©ation chunks | rad_chunk.py | 250-263 | Colonnes CSV perdues | **CRITIQUE** |
| Pinecone | rad_vectordb.py | 85-95 | Pas de m√©tadonn√©es CSV | **CRITIQUE** |
| Weaviate | rad_vectordb.py | 541-551 | Pas de m√©tadonn√©es CSV | **CRITIQUE** |
| Qdrant | rad_vectordb.py | 636-647 | Pas de m√©tadonn√©es CSV | **CRITIQUE** |

**Impact**: Les m√©tadonn√©es CSV personnalis√©es ne remontent pas dans les bases vectorielles, limitant s√©v√®rement les capacit√©s de filtrage.

**Solution recommand√©e**:
```python
# Remplacer les m√©tadonn√©es hardcod√©es par injection dynamique
metadata = {k: v for k, v in chunk.items()
            if k not in ("id", "embedding", "sparse_embedding", "text")}
```

### ‚úÖ **Optimisations de co√ªt impl√©ment√©es**

```python
# rad_chunk.py:232-237 - Logique de recodage intelligente
provider = str(row_data.get("texteocr_provider", "")).lower()
recode_required = provider not in ("mistral", "csv")  # ‚úÖ CSV skip GPT

# Support OpenRouter (√©conomie ~75%)
use_openrouter = "/" in model  # Auto-d√©tection provider/model
```

**R√©sultat**: CSV et Mistral OCR √©vitent automatiquement le recodage GPT co√ªteux.

---

## Architecture des tests

### üìã **Couverture de tests actuelle**

**Tests impl√©ment√©s** (excellente qualit√©):
- ‚úÖ **CSV ingestion pipeline** - 5 sc√©narios d√©taill√©s
- ‚úÖ **Client Zotero** - Tests int√©gration API
- ‚úÖ **G√©n√©ration notes LLM** - Validation contenu
- ‚úÖ **Classe Document** - Tests mod√®le de donn√©es
- ‚úÖ **Configuration** - Chargement settings et prompts

**Lacunes identifi√©es**:
- ‚ùå **Application FastAPI** - Pas de tests int√©gration endpoints
- ‚ùå **Op√©rations bases vectorielles** - Tests limit√©s Pinecone/Weaviate/Qdrant
- ‚ùå **Pipeline PDF** - OCR et extraction non test√©s
- ‚ùå **Cas d'erreur** - Tests n√©gatifs insuffisants
- ‚ùå **Performance** - Pas de tests charge

### üîß **Recommandations d'am√©lioration**

**Tests prioritaires √† ajouter**:
```python
# 1. Tests int√©gration FastAPI
@pytest.fixture
def test_client():
    return TestClient(app)

def test_upload_csv_endpoint(test_client):
    # Test complet upload CSV ‚Üí chunking ‚Üí embeddings
    
# 2. Tests bout-en-bout
def test_csv_to_vectordb_complete_pipeline():
    # CSV ‚Üí Document ‚Üí chunks ‚Üí embeddings ‚Üí insertion DB
    
# 3. Tests performance
def test_large_document_processing():
    # Benchmark 1000+ documents
```

---

## D√©pendances et √©cosyst√®me

### üì¶ **D√©pendances critiques**

```python
# Core pipeline
langchain-text-splitters==0.3.x  # Chunking intelligent
spacy==3.7.x                     # NLP fran√ßais
openai>=1.50.x                   # Embeddings + completion
pandas>=2.0.x                    # Manipulation donn√©es

# Vector databases
pinecone>=3.x                    # SDK v3+ Pinecone class
weaviate-client>=4.x             # Multi-tenancy support
qdrant-client>=1.x               # Vector search

# Web interface
fastapi>=0.100.x                 # API moderne
uvicorn>=0.24.x                  # ASGI server performant
python-multipart>=0.0.6          # Upload fichiers

# OCR et processing
mistralai>=1.x                   # OCR premium
pymupdf>=1.23.x                  # Fallback PDF
requests>=2.31.x                 # HTTP client
```

### üîí **Consid√©rations de s√©curit√©**

**Issues actuelles**:
- D√©pendances sans version √©pingl√©e ‚Üí vuln√©rabilit√©s potentielles
- CORS permissif en d√©veloppement
- Pas d'authentification sur endpoints sensibles
- Validation d'entr√©e limit√©e

**Recommandations**:
1. **√âpingler les versions** exactes dans requirements.txt
2. **Scan vuln√©rabilit√©s** avec `pip-audit` ou `safety`
3. **Authentification JWT** pour endpoints critiques
4. **Validation stricte** avec Pydantic models
5. **Rate limiting** sur endpoints API

---

## Roadmap et opportunit√©s

### üéØ **Am√©liorations prioritaires**

#### **Phase 1: R√©solution m√©tadonn√©es (CRITIQUE)**
```python
# Objectif: Permettre injection m√©tadonn√©es CSV dans bases vectorielles
# Effort: 2-3 jours d√©veloppement + tests
# Impact: D√©blocage complet des cas d'usage CSV

# Refactorisation rad_chunk.py
chunk_metadata = {
    "id": f"{doc_id}_{chunk_index}",
    "text": cleaned_text,
    **{k: v for k, v in row_data.items() 
       if k not in ["texteocr", "id", "text"]}  # Injection dynamique
}

# Refactorisation rad_vectordb.py (3 connecteurs)
metadata = {k: v for k, v in chunk.items()
            if k not in ["embedding", "sparse_embedding"]}
```

#### **Phase 2: Refactorisation app/main.py**
- D√©coupage en modules th√©matiques (auth, upload, processing, config)
- Extraction logique m√©tier vers services d√©di√©s
- Am√©lioration gestion d'erreurs et validation

#### **Phase 3: Tests et s√©curit√©**
- Suite tests int√©gration FastAPI
- Tests end-to-end pipeline complet
- Audit s√©curit√© et √©pinglage d√©pendances

### üöÄ **Fonctionnalit√©s futures**

**Am√©liorations techniques**:
- **Containerisation Docker** pour d√©ploiement simplifi√©
- **Processing distribu√©** pour gros corpus (Celery/RQ)
- **Cache intelligent** pour embeddings (Redis)
- **Monitoring observabilit√©** (m√©triques, traces)

**Fonctionnalit√©s utilisateur**:
- **Authentification multi-utilisateurs**
- **Gestion de projets** avec historique
- **API REST compl√®te** pour int√©grations externes
- **Tableau de bord** analytics et m√©triques

---

## Conclusion et recommandations

### ‚úÖ **Forces du syst√®me actuel**

1. **Architecture modulaire excellente** avec s√©paration claire des responsabilit√©s
2. **Pipeline robuste** supportant sources multiples et providers multiples
3. **Optimisation co√ªts avanc√©e** (OpenRouter, skip recodage intelligent)
4. **Interface utilisateur moderne** avec suivi temps r√©el (SSE)
5. **Int√©gration recherche acad√©mique** sophistiqu√©e (Zotero bidirectionnel)

### ‚ö†Ô∏è **Limitations critiques √† r√©soudre**

1. **M√©tadonn√©es hardcod√©es** emp√™chant l'exploitation compl√®te du CSV
2. **Monolithe app/main.py** n√©cessitant refactorisation urgente
3. **Tests d'int√©gration insuffisants** pour garantir la fiabilit√©
4. **S√©curit√©** inadapt√©e pour usage production

### üéØ **Action imm√©diate recommand√©e**

**Priorit√© absolue**: R√©soudre le probl√®me des m√©tadonn√©es hardcod√©es pour d√©bloquer compl√®tement l'ingestion CSV. Cette refactorisation permettra aux colonnes CSV personnalis√©es de se propager jusqu'aux bases vectorielles, ouvrant tous les cas d'usage de filtrage avanc√©.

**Effort estim√©**: 2-3 jours de d√©veloppement + 1 jour de tests
**Impact**: Transformation RAGpy en solution compl√®tement flexible pour tout type de donn√©es structur√©es

Le syst√®me RAGpy d√©montre d√©j√† des **fondations architecturales excellentes** et une **vision produit claire**. Avec la r√©solution des limitations identifi√©es, il peut devenir une solution RAG de r√©f√©rence pour la recherche acad√©mique et au-del√†.